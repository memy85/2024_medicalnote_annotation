{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook is to load the annotated dataset and work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: a EHR note (MIMIC)\n",
    "\n",
    "Instruction: Please identify 5~10 word tokens from the EHR note. Those 5~10 word tokens should be most important for a patient to understand their clinical conditions, procedures, and treatment plans.\n",
    "\n",
    "Output: keywords [use either human annotated, or just use MIMIC outputs\n",
    "[overlapping keywords between notes and discharge instructions- advantage: llama and GPT4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ======================================= Process annotation notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ========================================== Process with Rankings\n",
    "### creating 5 fold CV datasets\n",
    "- I will split 104 datasets into 5 folds (21,21,21,21,20)\n",
    "- save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "pages = ['victoria', 'jiaping', 'jinying-3A', 'jinying-2B-part1', 'jinying_2B_part2','jinying_3C']\n",
    "\n",
    "datas = []\n",
    "for page in pages :\n",
    "    # df = pd.read_excel(\"../data/raw/all_20160531.xlsx\", page)\n",
    "    df = pd.read_excel(\"../data/processed/all_20160531_changed.xlsx\", page)\n",
    "    datas.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, topn, ids = []) :\n",
    "    data = data.dropna(subset=['ranking']).copy()\n",
    "    # data = data.drop(columns = ['packet'])\n",
    "\n",
    "    data['fileid'] = data['fileid'].str.lower()\n",
    "    data['fileid'] = data['fileid'].str.strip()\n",
    "    data['fileid'] = data.fileid.str.replace('heart failure', 'heart_failure')\n",
    "    data['fileid'] = data.fileid.str.replace('liver failure', 'liver_failure')\n",
    "    data['fileid'] = data['fileid'].str.replace(\" \", \"\")\n",
    "    data['fileid'] = data['fileid'].apply(lambda x : x + '.txt' if not x.endswith('.txt') else x)\n",
    "\n",
    "    # process phrases\n",
    "    data['phrase'] = data['phrase'].str.lower()\n",
    "    data['phrase'] = data['phrase'].str.strip()\n",
    "\n",
    "    # process colors \n",
    "    data['color'] = data['color'].str.lower()\n",
    "    data['color'] = data['color'].replace({\"yellow\" : \"y\", \"green\" : \"g\"})\n",
    "\n",
    "    data = data.dropna()\n",
    "\n",
    "    # symptoms\n",
    "    symptoms = data[data.color == 'y'].sort_values(by=['fileid', 'ranking']).groupby(['fileid','color']).head(topn)\n",
    "    symptoms = symptoms.drop_duplicates(subset=['fileid', 'phrase'])\n",
    "\n",
    "    # tests\n",
    "    labtests = data[data.color == 'g'].sort_values(by=['fileid', 'ranking'])\n",
    "    labtests = labtests[labtests.ranking < (topn + 1)].copy()\n",
    "\n",
    "    result = pd.concat([symptoms, labtests], ignore_index=True)\n",
    "    result = result.sort_values(by=['fileid','ranking'])\n",
    "\n",
    "    # grouped = data.sort_values(by=['fileid','ranking'])\n",
    "    # result = grouped.groupby(['fileid']).head(topn)\n",
    "\n",
    "    result = result.drop_duplicates(subset=['fileid', 'ranking'])\n",
    "    result = result[~result.fileid.isin(ids)].reset_index(drop=True)\n",
    "    return result.reset_index(drop=True), result['fileid'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't erase this!\n",
    "example_text = \"cancer.report24.txt\"\n",
    "example_texts = [\"cancer.report24.txt\", \"diabetes.report310966.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = pd.concat(datas).fileid.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv(ids : list, nfold : int) :\n",
    "    random.shuffle(ids)\n",
    "    N = len(ids)\n",
    "\n",
    "    counts = N // nfold\n",
    "    leftover = N % nfold\n",
    "\n",
    "    indices = [counts for idx in range(1,nfold+1)]\n",
    "    indices = [idx + 1 if i < leftover else idx for i, idx in enumerate(indices)]\n",
    "\n",
    "    folds = []\n",
    "    past_idx = 0\n",
    "    for i, idx in enumerate(indices) :\n",
    "        idx += past_idx\n",
    "        if i == len(indices) :\n",
    "            folds.append(ids[past_idx:])\n",
    "        else :\n",
    "            folds.append(ids[past_idx:idx])\n",
    "        past_idx = idx\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "processed_datasets_top10 = []\n",
    "for data in datas :\n",
    "    processed, data_ids = preprocess_data(data, 10, ids)\n",
    "    processed_datasets_top10.append(processed)\n",
    "    ids.extend(data_ids)\n",
    "\n",
    "top10_dataset = pd.concat(processed_datasets_top10, ignore_index=True)\n",
    "top10_dataset = top10_dataset[~(top10_dataset.fileid.isin(example_texts))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileid</th>\n",
       "      <th>phrase</th>\n",
       "      <th>color</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>rheumatoid arthritis</td>\n",
       "      <td>y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>rituximan</td>\n",
       "      <td>g</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>osteoporosis</td>\n",
       "      <td>y</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>denosumab</td>\n",
       "      <td>g</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>hypercalcemic</td>\n",
       "      <td>g</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fileid                phrase color  ranking\n",
       "0  cancer.report28.txt  rheumatoid arthritis     y      1.0\n",
       "1  cancer.report28.txt             rituximan     g      1.1\n",
       "2  cancer.report28.txt          osteoporosis     y      2.0\n",
       "3  cancer.report28.txt             denosumab     g      2.1\n",
       "4  cancer.report28.txt         hypercalcemic     g      2.2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileids = top10_dataset.fileid.unique().tolist()\n",
    "cv5 = split_cv(fileids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hlo'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hello\".replace(\"el\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge with notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>noteid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liver_failure</td>\n",
       "      <td>liver_failure.report37286.txt</td>\n",
       "      <td>This is a 50-year-old male with a history of d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liver_failure</td>\n",
       "      <td>liver_failure.report37775.txt</td>\n",
       "      <td>Dr. name has discussed these results with you....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>liver_failure</td>\n",
       "      <td>liver_failure.report38874.txt</td>\n",
       "      <td>F/u on Osteoarthritis, chronic pain, HTN, Depr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liver_failure</td>\n",
       "      <td>liver_failure.report41972.txt</td>\n",
       "      <td>Very high a1c and glucose please follow up in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>liver_failure</td>\n",
       "      <td>liver_failure.report51432.txt</td>\n",
       "      <td>name is a lovely just turned 65-year-old gentl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                         noteid   \n",
       "0  liver_failure  liver_failure.report37286.txt  \\\n",
       "1  liver_failure  liver_failure.report37775.txt   \n",
       "2  liver_failure  liver_failure.report38874.txt   \n",
       "3  liver_failure  liver_failure.report41972.txt   \n",
       "4  liver_failure  liver_failure.report51432.txt   \n",
       "\n",
       "                                                text  \n",
       "0  This is a 50-year-old male with a history of d...  \n",
       "1  Dr. name has discussed these results with you....  \n",
       "2  F/u on Osteoarthritis, chronic pain, HTN, Depr...  \n",
       "3  Very high a1c and glucose please follow up in ...  \n",
       "4  name is a lovely just turned 65-year-old gentl...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = pd.read_pickle(\"../data/processed/notes.pkl\")\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# the data are 104 dataset\n",
    "files = top10_dataset['fileid'].unique()\n",
    "# file_top5 = top3_dataset['fileid'].unique()\n",
    "\n",
    "filtered_notes = notes[notes.noteid.isin(files)].reset_index(drop=True)\n",
    "\n",
    "# ============== Description!! ============== #\n",
    "# cv5 : 5 fold files\n",
    "# top 10 dataset : ranking information of 104 datas\n",
    "# filtered notes : the notes linked with top 10 dataset\n",
    "processed_ranking_datasets = (cv5, top10_dataset, filtered_notes)\n",
    "\n",
    "with open(\"../data/processed/cv_processed_ranking_datasets.pkl\", 'wb') as f :\n",
    "    pickle.dump(processed_ranking_datasets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from utils import format_prompt\n",
    "\n",
    "def save_to_json(list_of_dicts, name) :\n",
    "    with open(f\"../data/processed/finetune/{name}.json\", \"w\") as f :\n",
    "        json.dump(list_of_dicts, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * rule for naming\n",
    "# * Name should be cv0_rank3, cv0_rank5, ...\n",
    "\n",
    "for idx, cv in enumerate(cv5) : \n",
    "    for rank in [3,5,10] :\n",
    "        output = format_prompt(cv, rank)\n",
    "        name = f\"cv{idx}_rank{rank}\"\n",
    "        save_to_json(output, name)\n",
    "\n",
    "    # format_prompt(cv5[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "config = load_config()\n",
    "PROJECT_PATH = config.project_path\n",
    "DATA_PATH = PROJECT_PATH.joinpath(\"data/processed\")\n",
    "path = DATA_PATH.joinpath(\"cv_processed_ranking_datasets.pkl\")\n",
    "cv5, top10_dataset, filtered_notes = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39b1eb5e1054462a351ce40c8c93229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'noteid', 'text'],\n",
       "    num_rows: 83\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Dataset.from_pandas(filtered_notes)\n",
    "df.filter(lambda x : x['noteid'] not in cv5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileid</th>\n",
       "      <th>phrase</th>\n",
       "      <th>color</th>\n",
       "      <th>ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>rheumatoid arthritis</td>\n",
       "      <td>y</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>rituximan</td>\n",
       "      <td>g</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>osteoporosis</td>\n",
       "      <td>y</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>denosumab</td>\n",
       "      <td>g</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cancer.report28.txt</td>\n",
       "      <td>hypercalcemic</td>\n",
       "      <td>g</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>cancer.report3.txt</td>\n",
       "      <td>dystonic reaction</td>\n",
       "      <td>y</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>cancer.report3.txt</td>\n",
       "      <td>reglan</td>\n",
       "      <td>g</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>cancer.report3.txt</td>\n",
       "      <td>ivig</td>\n",
       "      <td>y</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>cancer.report3.txt</td>\n",
       "      <td>rigors and difficulty breathing with ivig</td>\n",
       "      <td>g</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>cancer.report3.txt</td>\n",
       "      <td>benadryl pretreatment</td>\n",
       "      <td>g</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   fileid  ... ranking\n",
       "0     cancer.report28.txt  ...     1.0\n",
       "1     cancer.report28.txt  ...     1.1\n",
       "2     cancer.report28.txt  ...     2.0\n",
       "3     cancer.report28.txt  ...     2.1\n",
       "4     cancer.report28.txt  ...     2.2\n",
       "...                   ...  ...     ...\n",
       "1137   cancer.report3.txt  ...     3.0\n",
       "1138   cancer.report3.txt  ...     3.1\n",
       "1139   cancer.report3.txt  ...     4.0\n",
       "1140   cancer.report3.txt  ...     4.1\n",
       "1141   cancer.report3.txt  ...     4.2\n",
       "\n",
       "[1142 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
