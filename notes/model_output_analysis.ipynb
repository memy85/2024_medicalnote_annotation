{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze the output of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "config = load_config()\n",
    "PROJECT_PATH = config.project_path\n",
    "DATA_PATH = PROJECT_PATH.joinpath('data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path\n",
    "\n",
    "MISTRAL7B = config.model_path('mistral7b')\n",
    "BIOMISTRAL7B = config.model_path('biomistral7b')\n",
    "MISTRAL7B_FINETUNED = config.model_path('mistral7b_finetuned')\n",
    "BIOMISTRAL7B_FINETUNED = config.model_path('biomistral7b_avigon_finetuned')\n",
    "MISTRAL7B_MIMIC_FINETUNED = config.model_path('mistral7b_mimic_finetuned')\n",
    "BIOMISTRAL7B_MIMIC_FINETUNED = config.model_path('biomistral7b_mimic_finetuned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example \n",
    "\n",
    "cv5, top10_dataset, filtered_notes = pd.read_pickle(DATA_PATH.joinpath(\"cv_processed_ranking_datasets.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to filter out only test dataset that were not in the train set\n",
    "# 1. let's filter out the test dataset\n",
    "\n",
    "wholedataset = set(top10_dataset.fileid.unique().tolist())\n",
    "trainset = set(cv5[0])\n",
    "testset = list(wholedataset - trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diabetes.report336006.txt', 'heart_failure.report51414.txt', 'liver_failure.report103978.txt']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "sample_files = random.sample(testset, 3)\n",
    "print(sample_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prompts and format data\n",
    "from datasets import Dataset\n",
    "\n",
    "def process_texts(samples, template) :\n",
    "\n",
    "    texts = samples['text']\n",
    "    formated_texts = []\n",
    "    for text in texts :\n",
    "        new_text = template.format(\n",
    "            context = text\n",
    "        )\n",
    "        formated_texts.append(new_text)\n",
    "    \n",
    "    return {\"questions\" : formated_texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a2ce7e3719403a9262365381ec07f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# process dataset with questions\n",
    "\n",
    "dataset = Dataset.from_pandas(filtered_notes)\n",
    "template = config.template(\"top5\", \"zeroshot\")\n",
    "dataset = dataset.map(process_texts, batched=True, fn_kwargs ={\"template\" : template})\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return text for input for model\n",
    "def return_text(sample_file) :\n",
    "    text = dataset[dataset.noteid == sample_file]['questions'].values.tolist()[0]\n",
    "    return text\n",
    "\n",
    "# process ranking\n",
    "def process_ranking(sample_file) :\n",
    "    ranking = top10_dataset[top10_dataset.fileid == sample_file]['ranking']\n",
    "    return ranking\n",
    "\n",
    "# process notes\n",
    "def process_notes(sample_file) :\n",
    "    notes = filtered_notes[filtered_notes.noteid == sample_file]['text']\n",
    "    notes = notes.values.tolist()[0]\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process gold label data\n",
    "def process_gold_label(sample_file) :\n",
    "    temp = top10_dataset[top10_dataset.fileid == sample_file][['phrase', 'ranking']].sort_values(by=\"ranking\")\n",
    "    gold_answer = \"\"\n",
    "    for _, row in temp.iterrows() :\n",
    "        gold_answer += str(row['ranking']) + ' ' + row['phrase'] + '\\n'\n",
    "    return gold_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from peft.peft_model import PeftModel\n",
    "\n",
    "DEFAULT_PAD_TOKEN = \"<pad>\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def load_model(model_path, finetune_flag=False):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "    if finetune_flag :\n",
    "        model = PeftModel.from_pretrained(model, model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tokenizer.add_special_tokens({\n",
    "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            })\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def infer_answers(text, model, tokenizer) :\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
    "    print(\"length of input ids are : \", len(input_ids))\n",
    "    output_ids = model.generate(input_ids=input_ids, \n",
    "                                max_new_tokens = 200)\n",
    "    \n",
    "    arr_output = output_ids.detach().cpu().numpy()\n",
    "    start_of_generate_index = input_ids.shape[1]\n",
    "    pred_output = tokenizer.batch_decode(arr_output[:, start_of_generate_index:], skip_special_tokens=True)[0]\n",
    "\n",
    "    return pred_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c374e984164548a3941dae8cdb206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nonischemic cardiomyopathy\n",
      "1.1 Persantine thallium stress test\n",
      "2. GERD\n",
      "2.1 EGD\n",
      "3. Fatty liver\n",
      "3.1 Hepatitis B and C serologies\n",
      "3.2 Ferritin\n",
      "3.3 Iron saturation\n",
      "3.4 Hepatitis B and C serologies\n",
      "3.5 Ceruloplasmin\n",
      "4. Hives\n",
      "4.1 EpiPen\n",
      "5. Sinus polyposis\n",
      "5.1 Polypectomy\n",
      "6. Asthma\n",
      "6.1 Dr. name\n",
      "7. Aspirin allergy\n",
      "7.1 Aspirin suppression\n",
      "8. Knee pain\n",
      "8.1 ER visit\n",
      "8.2 X-rays\n",
      "9. Left bicipital tendon tear\n",
      "9.1 Dent or bulge\n",
      "10. Colorectal cancer screening\n",
      "11.\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B_FINETUNED, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 nonischemic cardiomyopathy\n",
      "1.1 beta-blockers\n",
      "1.2 ace inhibitors\n",
      "2.0 hypertensive\n",
      "2.1 lipidation\n",
      "3.0 hepatitis\n",
      "3.1 ferritin\n",
      "3.2 iron saturation\n",
      "4.0 hepocromopathy\n",
      "5.0 hepatitis b and c serologies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B_MIMIC_FINETUNED, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nonischemic cardiomyopathy\n",
      "1.1. Persantine thallium test\n",
      "1.2. Echocardiogram\n",
      "2. GERD\n",
      "2.1. Proton pump inhibitor (PPI) therapy\n",
      "2.2. Endoscopy\n",
      "3. Fatty liver\n",
      "3.1. Iron saturation\n",
      "3.2. Ferritin levels\n",
      "4. Hives\n",
      "4.1. Antihistamines\n",
      "5. Sinus polyposis\n",
      "5.1. Nasal steroids\n",
      "6. Asthma\n",
      "6.1. Inhaled corticosteroids (ICS)\n",
      "7. Aspirin allergy\n",
      "7.1. Aspirin suppression\n",
      "8. Knee pain\n",
      "8.1. X-rays\n",
      "8.2. MRI of the knee\n",
      "9. Bicipital tendon tear\n",
      "9.1. Physical therapy (PT)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
