{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze the output of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "config = load_config()\n",
    "PROJECT_PATH = config.project_path\n",
    "DATA_PATH = PROJECT_PATH.joinpath('data/processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model path\n",
    "\n",
    "MISTRAL7B = config.model_path('mistral7b')\n",
    "BIOMISTRAL7B = config.model_path('biomistral7b')\n",
    "MISTRAL7B_FINETUNED = config.model_path('mistral7b_finetuned')\n",
    "BIOMISTRAL7B_FINETUNED = config.model_path('biomistral7b_avigon_finetuned')\n",
    "MISTRAL7B_MIMIC_FINETUNED = config.model_path('mistral7b_mimic_finetuned')\n",
    "BIOMISTRAL7B_MIMIC_FINETUNED = config.model_path('biomistral7b_mimic_finetuned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get example \n",
    "\n",
    "cv5, top10_dataset, filtered_notes = pd.read_pickle(DATA_PATH.joinpath(\"cv_processed_ranking_datasets.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer.report28.txt',\n",
       " 'cancer.report37.txt',\n",
       " 'cancer.report4.txt',\n",
       " 'cancer.report45.txt',\n",
       " 'cancer.report7.txt',\n",
       " 'copd.report100446.txt',\n",
       " 'copd.report101687.txt',\n",
       " 'copd.report26318.txt',\n",
       " 'copd.report34013.txt',\n",
       " 'copd.report50398.txt',\n",
       " 'diabetes.report111402.txt',\n",
       " 'diabetes.report152715.txt',\n",
       " 'diabetes.report274865.txt',\n",
       " 'diabetes.report284203.txt',\n",
       " 'diabetes.report351879.txt',\n",
       " 'heart_failure.report121015.txt',\n",
       " 'heart_failure.report1626.txt',\n",
       " 'heart_failure.report53467.txt',\n",
       " 'heart_failure.report71036.txt',\n",
       " 'heart_failure.report85881.txt',\n",
       " 'heart_failure.report94858.txt',\n",
       " 'cancer.report19.txt',\n",
       " 'cancer.report20.txt',\n",
       " 'cancer.report50.txt',\n",
       " 'copd.report25550.txt',\n",
       " 'copd.report26323.txt',\n",
       " 'copd.report43887.txt',\n",
       " 'copd.report63918.txt',\n",
       " 'copd.report88353.txt',\n",
       " 'copd.report99185.txt',\n",
       " 'diabetes.report148624.txt',\n",
       " 'diabetes.report179434.txt',\n",
       " 'diabetes.report232392.txt',\n",
       " 'diabetes.report252700.txt',\n",
       " 'diabetes.report413488.txt',\n",
       " 'heart_failure.report129820.txt',\n",
       " 'heart_failure.report133488.txt',\n",
       " 'heart_failure.report29683.txt',\n",
       " 'heart_failure.report36848.txt',\n",
       " 'heart_failure.report60059.txt',\n",
       " 'heart_failure.report80980.txt',\n",
       " 'hypertension.report35952.txt',\n",
       " 'hypertension.report409078.txt',\n",
       " 'hypertension.report440197.txt',\n",
       " 'hypertension.report632569.txt',\n",
       " 'hypertension.report74246.txt',\n",
       " 'liver_failure.report103601.txt',\n",
       " 'liver_failure.report37286.txt',\n",
       " 'liver_failure.report51432.txt',\n",
       " 'liver_failure.report55225.txt',\n",
       " 'liver_failure.report60517.txt',\n",
       " 'cancer.report23.txt',\n",
       " 'cancer.report27.txt',\n",
       " 'cancer.report35.txt',\n",
       " 'cancer.report5.txt',\n",
       " 'cancer.report8.txt',\n",
       " 'copd.report100253.txt',\n",
       " 'copd.report39913.txt',\n",
       " 'copd.report69375.txt',\n",
       " 'copd.report79717.txt',\n",
       " 'copd.report835.txt',\n",
       " 'diabetes.report120437.txt',\n",
       " 'diabetes.report139874.txt',\n",
       " 'diabetes.report335782.txt',\n",
       " 'diabetes.report336006.txt',\n",
       " 'diabetes.report391725.txt',\n",
       " 'diabetes.report67496.txt',\n",
       " 'heart_failure.report131230.txt',\n",
       " 'heart_failure.report13695.txt',\n",
       " 'heart_failure.report31898.txt',\n",
       " 'heart_failure.report69080.txt',\n",
       " 'heart_failure.report73433.txt',\n",
       " 'hypertension.report102254.txt',\n",
       " 'hypertension.report160752.txt',\n",
       " 'hypertension.report75883.txt',\n",
       " 'hypertension.report849850.txt',\n",
       " 'hypertension.report879785.txt',\n",
       " 'hypertension.report916152.txt',\n",
       " 'liver_failure.report115804.txt',\n",
       " 'liver_failure.report119902.txt',\n",
       " 'liver_failure.report28601.txt',\n",
       " 'liver_failure.report32013.txt',\n",
       " 'liver_failure.report41972.txt',\n",
       " 'cancer.report13.txt',\n",
       " 'cancer.report14.txt',\n",
       " 'cancer.report15.txt',\n",
       " 'copd.report17259.txt',\n",
       " 'copd.report39915.txt',\n",
       " 'copd.report88348.txt',\n",
       " 'diabetes.report178889.txt',\n",
       " 'diabetes.report298124.txt',\n",
       " 'heart_failure.report103868.txt',\n",
       " 'heart_failure.report127307.txt',\n",
       " 'heart_failure.report128463.txt',\n",
       " 'heart_failure.report51414.txt',\n",
       " 'hypertension.report150050.txt',\n",
       " 'hypertension.report741579.txt',\n",
       " 'hypertension.report811078.txt',\n",
       " 'hypertension.report938733.txt',\n",
       " 'liver_failure.report10101.txt',\n",
       " 'liver_failure.report103978.txt',\n",
       " 'cancer.report11.txt',\n",
       " 'cancer.report18.txt',\n",
       " 'cancer.report3.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to filter out only test dataset that were not in the train set\n",
    "\n",
    "set(top10_dataset.fileid.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liver_failure.report55225.txt', 'hypertension.report811078.txt', 'cancer.report35.txt']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "sample_file = random.sample(top10_dataset.fileid.unique().tolist(), 3)\n",
    "print(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process ranking\n",
    "ranking = top10_dataset[top10_dataset.fileid == sample_file]\n",
    "\n",
    "# process notes\n",
    "notes = filtered_notes[filtered_notes.noteid == sample_file]['text']\n",
    "notes = notes.values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccfd18a10f040628b359ea36a295b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load prompts and format data\n",
    "from datasets import Dataset\n",
    "\n",
    "def process_texts(samples, template) :\n",
    "\n",
    "    texts = samples['text']\n",
    "    formated_texts = []\n",
    "    for text in texts :\n",
    "        new_text = template.format(\n",
    "            context = text\n",
    "        )\n",
    "        formated_texts.append(new_text)\n",
    "    \n",
    "    return {\"questions\" : formated_texts}\n",
    "\n",
    "dataset = Dataset.from_pandas(filtered_notes)\n",
    "template = config.template(\"top5\", \"zeroshot\")\n",
    "dataset = dataset.map(process_texts, batched=True, fn_kwargs ={\"template\" : template})\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "You are a helpful assistant, an expert in medical domain. \n",
      "Extract top 5 main diagnosis/symptoms or conditions mentioned in the medical note. \n",
      "Following the diagnosis/symptoms or conditions, identify the medical tests related to it.\n",
      "If there isn't any medical tests related to it, just start listing the next important diagnosis/symptoms or conditions.\n",
      "If there are no additional diagnosis/symptoms or conditions that you can identify, just list the existing ones and finalize the output. \n",
      "Don't write no symptoms, or any indication that there is no other diagnosis/symptoms or conditions.\n",
      "Do not modify or abbreviate what is written in the notes. Just extract them as they are.\n",
      "Make sure the highest priority is assigned with a smaller number.\n",
      "We give you an example, do follow as below.\n",
      "The format should be as follows\n",
      "\n",
      "1. key symptom or condition\n",
      "1.1 medical test related to 1\n",
      "1.2 medical test related to 1\n",
      "\n",
      "2. key symptom or condition\n",
      "2.1 medical test related to 2\n",
      "\n",
      "3. key symptom or condition\n",
      "3.1 medical test related to 3\n",
      "3.2 medical test related to 3\n",
      "\n",
      "4. key symptom or condition\n",
      "4.1 medical test related to 4\n",
      "\n",
      "5. key symptom or condition\n",
      "5.1 medical test related to 5\n",
      "5.2 medical test related to 5\n",
      "\n",
      "### Context: \n",
      "{context}\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataset[dataset.noteid == sample_file]['questions'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 nonischemic cardiomyopathy\n",
      "1.1 persantine thallium\n",
      "1.2 ejection fraction\n",
      "1.3 lad ischemia\n",
      "1.4 heart catheterization\n",
      "1.5 carvedilol\n",
      "2.0 trigger fingers\n",
      "2.1 hand clinic\n",
      "2.2 mri\n",
      "3.0 health maintenance\n",
      "3.2 prevnar vaccine\n",
      "3.3 tetanus\n",
      "3.4 psa\n",
      "4.0 knee pain\n",
      "4.1 x-rays\n",
      "4.2 mri of the left knee\n",
      "4.3 arthritis\n",
      "4.4 some therapy\n",
      "4.5 orthopedic evaluation\n",
      "5.0 gerd\n",
      "6.0 fatty liver\n",
      "6.1 elevated liver enzymes\n",
      "6.2 hemochromatosis gene analysis shows he has only heterozygote for h63d\n",
      "7.0 hypertension\n",
      "7.1 losartan potassium and hydrochlorothiazide\n",
      "7.2 carvedilol\n",
      "8.0 asthma\n",
      "9.0 aspirin allergy\n",
      "10.0 left bicipital tendon\n",
      "10.1 colorectal cancer screening\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process gold label data\n",
    "\n",
    "temp = top10_dataset[top10_dataset.fileid == sample_file][['phrase', 'ranking']].sort_values(by=\"ranking\")\n",
    "gold_answer = \"\"\n",
    "for _, row in temp.iterrows() :\n",
    "    gold_answer += str(row['ranking']) + ' ' + row['phrase'] + '\\n'\n",
    "print(gold_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from peft.peft_model import PeftModel\n",
    "\n",
    "DEFAULT_PAD_TOKEN = \"<pad>\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "def load_model(model_path, finetune_flag=False):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "    if finetune_flag :\n",
    "        model = PeftModel.from_pretrained(model, model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    tokenizer.add_special_tokens({\n",
    "                \"eos_token\": DEFAULT_EOS_TOKEN,\n",
    "                \"bos_token\": DEFAULT_BOS_TOKEN,\n",
    "                \"unk_token\": DEFAULT_UNK_TOKEN,\n",
    "            })\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def infer_answers(text, model, tokenizer) :\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.cuda()\n",
    "    print(\"length of input ids are : \", len(input_ids))\n",
    "    output_ids = model.generate(input_ids=input_ids, \n",
    "                                max_new_tokens = 200)\n",
    "    \n",
    "    arr_output = output_ids.detach().cpu().numpy()\n",
    "    start_of_generate_index = input_ids.shape[1]\n",
    "    pred_output = tokenizer.batch_decode(arr_output[:, start_of_generate_index:], skip_special_tokens=True)[0]\n",
    "\n",
    "    return pred_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c374e984164548a3941dae8cdb206e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nonischemic cardiomyopathy\n",
      "1.1 Persantine thallium stress test\n",
      "2. GERD\n",
      "2.1 EGD\n",
      "3. Fatty liver\n",
      "3.1 Hepatitis B and C serologies\n",
      "3.2 Ferritin\n",
      "3.3 Iron saturation\n",
      "3.4 Hepatitis B and C serologies\n",
      "3.5 Ceruloplasmin\n",
      "4. Hives\n",
      "4.1 EpiPen\n",
      "5. Sinus polyposis\n",
      "5.1 Polypectomy\n",
      "6. Asthma\n",
      "6.1 Dr. name\n",
      "7. Aspirin allergy\n",
      "7.1 Aspirin suppression\n",
      "8. Knee pain\n",
      "8.1 ER visit\n",
      "8.2 X-rays\n",
      "9. Left bicipital tendon tear\n",
      "9.1 Dent or bulge\n",
      "10. Colorectal cancer screening\n",
      "11.\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B_FINETUNED, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 nonischemic cardiomyopathy\n",
      "1.1 beta-blockers\n",
      "1.2 ace inhibitors\n",
      "2.0 hypertensive\n",
      "2.1 lipidation\n",
      "3.0 hepatitis\n",
      "3.1 ferritin\n",
      "3.2 iron saturation\n",
      "4.0 hepocromopathy\n",
      "5.0 hepatitis b and c serologies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of input ids are :  1\n"
     ]
    }
   ],
   "source": [
    "# test inference\n",
    "\n",
    "model, tokenizer = load_model(BIOMISTRAL7B_MIMIC_FINETUNED, False)\n",
    "answers = infer_answers(text=text, model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Nonischemic cardiomyopathy\n",
      "1.1. Persantine thallium test\n",
      "1.2. Echocardiogram\n",
      "2. GERD\n",
      "2.1. Proton pump inhibitor (PPI) therapy\n",
      "2.2. Endoscopy\n",
      "3. Fatty liver\n",
      "3.1. Iron saturation\n",
      "3.2. Ferritin levels\n",
      "4. Hives\n",
      "4.1. Antihistamines\n",
      "5. Sinus polyposis\n",
      "5.1. Nasal steroids\n",
      "6. Asthma\n",
      "6.1. Inhaled corticosteroids (ICS)\n",
      "7. Aspirin allergy\n",
      "7.1. Aspirin suppression\n",
      "8. Knee pain\n",
      "8.1. X-rays\n",
      "8.2. MRI of the knee\n",
      "9. Bicipital tendon tear\n",
      "9.1. Physical therapy (PT)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
